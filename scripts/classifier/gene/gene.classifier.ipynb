{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/jiamingqu/Desktop/proj/scripts/classifier/gene/gene.parsing.functions.ipynb\n",
    "%run /Users/jiamingqu/Desktop/proj/scripts/searching/query.expansion.ipynb\n",
    "%run /Users/jiamingqu/Desktop/proj/scripts/classifier/read.dataframe.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_kb = pd.read_csv(\"/Users/jiamingqu/Desktop/2017.2018/data/knowledge.base/Homo_sapiens.gene_info\", sep=\"\\t\", index_col=False)\n",
    "variations_kb = pd.read_csv(\"/Users/jiamingqu/Desktop/2017.2018/data/knowledge.base/PMKB_Interpretations_Complete_20191118-1534.csv\", \\\n",
    "                             sep=\",\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_alias_and_variations(gene, aliases = alias_kb, variations=variations_kb):\n",
    "    \n",
    "    '''\n",
    "    Get a gene's aliases and all its variants\n",
    "    Args:\n",
    "        gene name, alias knowledge base, variations knowledge base\n",
    "    Returns:\n",
    "        a dictionary of {\"alias\": [], \"variants\": []}\n",
    "    '''\n",
    "    \n",
    "    dic = {}\n",
    "    \n",
    "    # add aliases\n",
    "    aliases = aliases[[\"Symbol\", \"Synonyms\"]]\n",
    "    if gene in list(aliases.Symbol):\n",
    "        dic[\"aliases\"] = aliases.loc[aliases.Symbol==gene].Synonyms.values[0].split(\"|\")\n",
    "    else:\n",
    "        dic[\"aliases\"] = []\n",
    "    \n",
    "    # add variants\n",
    "    if gene in list(variations.Gene):\n",
    "        # may have several records\n",
    "        df_gene_variations = variations.loc[variations.Gene == gene]\n",
    "        variation_list = []\n",
    "        \n",
    "        # iterate the result df\n",
    "        for index,row in df_gene_variations.iterrows():\n",
    "            \n",
    "            # one record in the df\n",
    "            gene_variations = df_gene_variations.loc[index, \"Variant(s)\"]\n",
    "            for i in str(gene_variations).split(\"|\"):\n",
    "                i_cleaned = i.replace(gene, \"\")\n",
    "                variation_list.append(i_cleaned.strip())\n",
    "                \n",
    "        # de-dup\n",
    "        dic[\"variants\"] = list(set(variation_list))\n",
    "    else:\n",
    "        dic[\"variants\"] = []\n",
    "        \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(year):\n",
    "    \n",
    "    # read parsed gene dataframe\n",
    "    gene_df = parsing_gene_raw_judgements(year)\n",
    "    \n",
    "    # feature table\n",
    "    feature_table = pd.DataFrame(columns=[\"match_gene\", \n",
    "                                          \"has_variation\", \"match_variation\", \"match_total_variation\",\n",
    "                                          \"has_other_info\", \"match_other_info\", \n",
    "                                          \"topicid\",\"docid\",\"label\"])\n",
    "    # folder path of the corpus\n",
    "    folder_path = \"../../../data/corpus/\"\n",
    "    \n",
    "    # start generating features, iterate through topics\n",
    "    for topic in set(gene_df.topicid):\n",
    "        \n",
    "        print(\"Start parsing topic {}\".format(topic))\n",
    "        \n",
    "        sub_gene_df = gene_df.loc[gene_df.topicid == topic]\n",
    "        \n",
    "        # iterate through documents\n",
    "        for index,rows in sub_gene_df.iterrows():\n",
    "        \n",
    "            # read documents\n",
    "            docid = sub_gene_df.loc[index, \"docid\"]\n",
    "            lines = []\n",
    "            with open(folder_path+docid+\".txt\",'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    lines.append(line.strip())\n",
    "            full_text = \" \".join(lines)\n",
    "            \n",
    "            query_gene = sub_gene_df.loc[index,\"gene\"]\n",
    "            genes,variant,other_info = parsing_query_gene(query_gene)\n",
    "        \n",
    "            # 1) match gene\n",
    "            match_gene = 0\n",
    "            for gene in genes:\n",
    "                if \" \" not in gene: \n",
    "                    match_gene += full_text.count(gene)\n",
    "                    aliases = get_gene_alias_and_variations(gene)[\"aliases\"]\n",
    "                    for alias in aliases:\n",
    "                        match_gene += full_text.count(alias)\n",
    "                else: # special case: the gene is a phrase\n",
    "                    for g in gene.split(\" \"):\n",
    "                        g = g.strip()\n",
    "                        match_gene += full_text.lower().count(g.lower())\n",
    "                    \n",
    "\n",
    "            # 2) match variation\n",
    "            if variant != 0:\n",
    "                has_variation,match_variation,match_total_variation = 1,0,0\n",
    "                # match variation\n",
    "                match_variation += full_text.count(variant)\n",
    "                # match all the variations\n",
    "                for gene in genes:\n",
    "                    variants = get_gene_alias_and_variations(gene)[\"variants\"]\n",
    "                    for v in variants:\n",
    "                        match_total_variation += full_text.count(v)\n",
    "            else:\n",
    "                has_variation,match_variation,match_total_variation = 0,0,0\n",
    "                # match all the variations\n",
    "                for gene in genes:\n",
    "                    variants = get_gene_alias_and_variations(gene)[\"variants\"]\n",
    "                    for v in variants:\n",
    "                        match_total_variation += full_text.count(v)\n",
    "\n",
    "                        \n",
    "            # 3) match other info\n",
    "            if other_info != 0:\n",
    "                has_other_info, match_other_info = 1,0\n",
    "                for o in other_info.split(\" \"):\n",
    "                    o = o.strip()\n",
    "                    match_other_info += full_text.lower().count(o.lower())\n",
    "            else:\n",
    "                has_other_info, match_other_info = 0,0\n",
    "\n",
    "                \n",
    "            topicid = sub_gene_df.loc[index,\"topicid\"]\n",
    "            docid = sub_gene_df.loc[index,\"docid\"]\n",
    "            label = sub_gene_df.loc[index,\"label\"]\n",
    "\n",
    "            feature_table = feature_table.append({\"match_gene\": match_gene, \n",
    "                                                  \"has_variation\": has_variation, \n",
    "                                                  \"match_variation\": match_variation, \n",
    "                                                  \"match_total_variation\": match_total_variation,\n",
    "                                                  \"has_other_info\": has_other_info, \n",
    "                                                  \"match_other_info\":match_other_info,\n",
    "                                                  \"topicid\":topic,\n",
    "                                                  \"docid\":docid,\n",
    "                                                  \"label\":label}, ignore_index=True)\n",
    "            \n",
    "        print(\"Topic {} has been parsed\".format(topic))\n",
    "        \n",
    "    # sanity check and save results\n",
    "    assert feature_table.shape[0] == gene_df.shape[0]\n",
    "    feature_table.to_csv(str(year) + \".gene.features.csv\", index=False, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate_features(2017)\n",
    "# generate_features(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_testing_classifier(training_years, testing_years):\n",
    "    \n",
    "    df_list=[]\n",
    "    for year in training_years:\n",
    "        df = pd.read_csv(str(year)+\".gene.features.csv\")\n",
    "        df_list.append(df)\n",
    "    df_training=pd.concat(df_list)\n",
    "    df_testing=pd.read_csv(str(testing_years)+\".gene.features.csv\")\n",
    "    \n",
    "    features = [\"match_gene\", \"has_variation\", \"match_variation\", \"match_total_variation\",\n",
    "                \"has_other_info\", \"match_other_info\"]\n",
    "    training_features=df_training[features]\n",
    "    testing_features=df_testing[features]\n",
    "    training_labels=df_training.label\n",
    "    testing_labels=df_testing.label\n",
    "    \n",
    "    # over-sampling\n",
    "    training_features, training_labels = SMOTE().fit_resample(training_features, training_labels)\n",
    "    \n",
    "    # training\n",
    "    logistic_model = LogisticRegression(multi_class=\"ovr\", penalty='l2', C=0.5, max_iter=5000)\n",
    "    logistic_model.fit(training_features, training_labels)\n",
    "    \n",
    "    predicted_labels = logistic_model.predict(testing_features)\n",
    "    print(classification_report(testing_labels, predicted_labels))\n",
    "    \n",
    "    joblib.dump(logistic_model, str(testing_years)+\".gene.classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Different Variant       0.04      0.10      0.06       846\n",
      "            Exact       0.75      0.39      0.51      4425\n",
      "     Missing Gene       0.61      0.71      0.66      2226\n",
      "  Missing Variant       0.33      0.52      0.41      1208\n",
      "\n",
      "         accuracy                           0.46      8705\n",
      "        macro avg       0.43      0.43      0.41      8705\n",
      "     weighted avg       0.59      0.46      0.49      8705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training_testing_classifier([2017],2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_original_distribution(training_years):\n",
    "    \n",
    "    df_list=[]\n",
    "    for year in training_years:\n",
    "        df = pd.read_csv(str(year)+\".gene.features.csv\")\n",
    "        df_list.append(df)\n",
    "    df_training=pd.concat(df_list)\n",
    "    \n",
    "    print(df_training.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact                4578\n",
      "Missing Gene         3696\n",
      "Missing Variant      1551\n",
      "Different Variant     602\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print_original_distribution([2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
