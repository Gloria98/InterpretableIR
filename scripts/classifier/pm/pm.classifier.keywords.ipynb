{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/jiamingqu/Desktop/proj/scripts/classifier/read.dataframe.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(\"english\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove punctuation and new line characters\n",
    "    text.replace(\"\\t\",\" \")\n",
    "    text.replace(\"\\n\",\" \")\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    \n",
    "    # remove digits\n",
    "    text = re.sub(r\"\\b\\d+\\b\",\" \", text)\n",
    "    \n",
    "    # remove multiple white spaces\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    # remove stopwords\n",
    "    text = [x for x in text.split() if x not in stop]\n",
    "    \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(year):\n",
    "    \n",
    "    # read parsed gene dataframe\n",
    "    pm_df = read_dataframe(year, \"pm\")\n",
    "    \n",
    "    # feature table\n",
    "    feature_table = pd.DataFrame(columns=[\"match_human\",\"match_animal\",\"match_not\", \n",
    "                                          \"topicid\",\"docid\",\"label\"])\n",
    "    # folder path of the corpus\n",
    "    folder_path = \"../../../data/corpus/\"\n",
    "    \n",
    "    keyword_animal = ['mice', 'mouse', 'model', 'mammary', \n",
    "                  'rat','xenografts','rats','models',\n",
    "                  'vivo','cycle','mutated','preclinical',\n",
    "                  'prostate','pten','liver','met','animals',\n",
    "                  'mgkg','human', 'xenograft']\n",
    "\n",
    "    keyword_human = ['gastrectomy','imatinib','gastric','stomach',\n",
    "                 'fgfr1','prognostic','mutation','gastrointestinal',\n",
    "                 'mutations','families','shorter','inhibitor',\n",
    "                 'kit','located','lethal','kras','dose',\n",
    "                 'tract','pfs','mutated']\n",
    "\n",
    "    keyword_not = ['lung','transplantation','symptoms','female',\n",
    "               'apoptotic','driver','cervical','pressure',\n",
    "               'pancreaticoduodenectomy','surface','triple','women',\n",
    "               'however','a549','cervix','mortality','adjuvant',\n",
    "               'bypass','basis','myxoid']\n",
    "        \n",
    "    # iterate through documents\n",
    "    for index,rows in pm_df.iterrows():\n",
    "\n",
    "        # read documents\n",
    "        docid = str(pm_df.loc[index, \"trec_doc_id\"])\n",
    "        lines = []\n",
    "        with open(folder_path+docid+\".txt\",'r') as f:\n",
    "            for line in f.readlines():\n",
    "                lines.append(line.strip())\n",
    "        full_text = \" \".join(lines)\n",
    "        full_text = clean_text(full_text)\n",
    "        \n",
    "        match_human = 0\n",
    "        match_animal = 0\n",
    "        match_not = 0\n",
    "        \n",
    "        \n",
    "        for k in keyword_human:\n",
    "            match_human += full_text.count(k)\n",
    "        \n",
    "        for k in keyword_animal:\n",
    "            match_animal += full_text.count(k)\n",
    "            \n",
    "        for k in keyword_not:\n",
    "            match_not += full_text.count(k)\n",
    "\n",
    "\n",
    "        topicid = pm_df.loc[index,\"trec_topic_number\"]\n",
    "        label = pm_df.loc[index,\"pm_rel_desc\"]\n",
    "\n",
    "        feature_table = feature_table.append({\"match_human\":match_human,\n",
    "                                              \"match_animal\":match_animal,\n",
    "                                              \"match_not\":match_not, \n",
    "                                              \"topicid\":topicid,\n",
    "                                              \"docid\":docid,\n",
    "                                              \"label\":label}, ignore_index=True)\n",
    "\n",
    "        if index%1000==0:\n",
    "            print(index)\n",
    "\n",
    "    # sanity check and save results\n",
    "    assert feature_table.shape[0] == pm_df.shape[0]\n",
    "    feature_table.to_csv(str(year) + \".pm.features.csv\", index=False, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate_features(2017)\n",
    "# generate_features(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_testing_classifier(training_years, testing_years):\n",
    "    \n",
    "    df_list=[]\n",
    "    for year in training_years:\n",
    "        df = pd.read_csv(str(year)+\".pm.features.csv\")\n",
    "        df_list.append(df)\n",
    "    df_training=pd.concat(df_list)\n",
    "    df_testing=pd.read_csv(str(testing_years)+\".pm.features.csv\")\n",
    "    \n",
    "    features = [\"match_human\",\"match_animal\",\"match_not\"]\n",
    "    training_features=df_training[features]\n",
    "    testing_features=df_testing[features]\n",
    "    training_labels=df_training.label\n",
    "    testing_labels=df_testing.label\n",
    "    \n",
    "    # over-sampling\n",
    "    training_features, training_labels = SMOTE().fit_resample(training_features, training_labels)\n",
    "    \n",
    "    # training\n",
    "    logistic_model = LogisticRegression(multi_class=\"ovr\", C=0.5)\n",
    "    logistic_model.fit(training_features, training_labels)\n",
    "    \n",
    "    predicted_labels = logistic_model.predict(testing_features)\n",
    "    print(classification_report(testing_labels, predicted_labels))\n",
    "    \n",
    "    joblib.dump(logistic_model, str(testing_years)+\".pm.classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Animal PM       0.10      0.63      0.17       590\n",
      "    Human PM       0.59      0.41      0.48      8634\n",
      "      Not PM       0.72      0.68      0.70     13205\n",
      "\n",
      "    accuracy                           0.58     22429\n",
      "   macro avg       0.47      0.57      0.45     22429\n",
      "weighted avg       0.65      0.58      0.60     22429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training_testing_classifier([2017],2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_original_distribution(training_years):\n",
    "    \n",
    "    df_list=[]\n",
    "    for year in training_years:\n",
    "        df = pd.read_csv(str(year)+\".pm.features.csv\")\n",
    "        df_list.append(df)\n",
    "    df_training=pd.concat(df_list)\n",
    "    \n",
    "    print(df_training.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not PM       13368\n",
      "Human PM      8738\n",
      "Animal PM      536\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print_original_distribution([2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
